# Ollama_chat_application
A real-time multi-room chat application built with Flask(backend) and Streamlit (frontend), powered by Ollama for on-device LLM inference (e.g., LLaMA3). Easily deployable using Docker &amp; Docker Compose.
